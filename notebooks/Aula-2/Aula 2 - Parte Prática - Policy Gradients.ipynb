{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 2 - Parte Prática - Policy Gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Nesse segundo notebook vamos aprender ...\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "- Entender a abordagem de otimização de políticas como busca no espaço de parâmetros da política\n",
    "- Implementar um primeiro agente baseado no algoritmo REINFORCE\n",
    "- Familiarizar-se com a API básica de construção de modelos (i.e., redes neurais) em Keras\n",
    "- Familiarizar-se com métodos de Deep Learning usando TensorFlow 2.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "> **Atenção:** não se esqueça de executar todos os `imports` necessários antes prosseguir com o tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tf.__version__ == '2.1.0'\n",
    "assert tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementando políticas estocásticas em tf.Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Caso discreto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, input_shape=(5,), activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(3),\n",
    "    tfp.layers.DistributionLambda(lambda t: tfd.Categorical(logits=t))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.32103857 -0.6080192   1.4877108  -0.12977777 -1.1860949 ]\n",
      " [ 0.02536139  1.1291535  -0.07863023 -0.9902698   0.8496303 ]\n",
      " [ 0.44752735 -1.3599901   0.12103056 -0.712829    0.9447562 ]\n",
      " [-0.9185843   0.947765    0.57675695 -0.04887169 -0.954858  ]\n",
      " [-0.6540133   0.8262241  -0.39020407 -0.9625042  -0.3470074 ]\n",
      " [ 1.4613252   2.0669453   0.17619659  0.09371976  0.04527772]\n",
      " [ 0.62663805 -0.09943198  0.40964445 -1.9779913   0.6893666 ]\n",
      " [-1.7095194   1.4237188   0.09787725  1.3101344   0.4518444 ]\n",
      " [-0.9198294  -0.6814246  -1.1695627  -1.6370764  -0.41971138]\n",
      " [ 0.2589838   1.6075752  -0.3090215   0.07801837  0.13695426]], shape=(10, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.random.normal(shape=(10, 5))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Categorical(\"sequential_7_distribution_lambda_7_Categorical\", batch_shape=[10], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dist = model(inputs)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 1 0 2 2 0 1 2 2], shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "sample = dist.sample()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.9802021  -1.3386791  -1.0007324  -1.028725   -1.406725   -1.4265188\n",
      " -0.98318666 -1.045281   -1.8600569  -1.2781339 ], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample_log_prob = dist.log_prob(sample)\n",
    "print(sample_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discrete_policy(obs_space, action_space, hidden_layers, activation):\n",
    "    Dense = tf.keras.layers.Dense\n",
    "    DistributionLambda = tfp.layers.DistributionLambda\n",
    "    Categorical = tfd.Categorical\n",
    "    \n",
    "    policy_net_layers = []\n",
    "    \n",
    "    for i, units in enumerate(hidden_layers):\n",
    "        if i == 0:\n",
    "            policy_net_layers.append(Dense(units=units, activation=activation, input_shape=obs_space.shape))\n",
    "        else:\n",
    "            policy_net_layers.append(Dense(units=units, activation=activation))\n",
    "    \n",
    "    policy_net_layers.append(Dense(units=action_space.n))\n",
    "    policy_net_layers.append(DistributionLambda(lambda t: Categorical(logits=t)))\n",
    "                                     \n",
    "    return tf.keras.Sequential(policy_net_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Categorical(\"sequential_29_distribution_lambda_29_Categorical\", batch_shape=[1], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "hidden_layers = [64, 64]\n",
    "activation = \"relu\"\n",
    "\n",
    "policy = build_discrete_policy(env.observation_space, env.action_space, hidden_layers, activation)\n",
    "\n",
    "obs = env.observation_space.sample()\n",
    "\n",
    "action_dist = policy(obs[None,:])\n",
    "print(action_dist)\n",
    "\n",
    "action = action_dist.sample().numpy()\n",
    "assert action[0] in env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Caso contínuo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=\"tanh\", input_shape=(10,)),\n",
    "    tf.keras.layers.Dense(128, activation=\"tanh\"),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tfp.layers.DistributionLambda(lambda t: tfd.MultivariateNormalDiag(loc=t, scale_diag=[1e-2] * 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.8419557   0.70250314 -1.5014496   0.18716766 -0.75787574 -1.0289555\n",
      "   0.01592047 -0.6249459   1.0384505  -1.184295  ]\n",
      " [ 1.556421    0.5781917  -1.6744963  -0.31686938 -0.7645374   1.3680733\n",
      "  -0.24784766 -1.4356192   0.09560852 -1.3406086 ]\n",
      " [ 0.5428561  -0.4105987   0.79216933  0.85922605 -2.2289503   0.35503837\n",
      "  -1.2095629   1.2945596   1.7793185   0.1548357 ]\n",
      " [-0.77329165  0.33763334  0.46752357 -0.3361535  -0.14248116  0.06044088\n",
      "   0.5058375  -0.56888855 -0.08033823 -0.12951943]], shape=(4, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.random.normal(shape=(4, 10))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalDiag(\"sequential_14_distribution_lambda_14_MultivariateNormalDiag\", batch_shape=[4], event_shape=[10], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dist = model(inputs)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.02107014  0.67111677 -0.05717062 -0.10963654  0.30163962 -0.20284596\n",
      "  -0.31478062  0.4405437  -0.45328838  0.4712263 ]\n",
      " [ 0.7728581   0.47813922  0.01443296 -0.24912257 -0.9230962   0.01782654\n",
      "  -0.25555795  0.18761869 -0.2212125   0.21795002]\n",
      " [ 0.2327961  -0.4189296   0.47730008  0.10519981 -0.3640216   0.29068133\n",
      "   0.0499337  -0.77466166  0.03433217 -0.42330003]\n",
      " [-0.16805093  0.09478584  0.15372992  0.00448452  0.26795706 -0.2142506\n",
      "  -0.00713969  0.39221483 -0.07863823  0.16443925]], shape=(4, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample = dist.sample()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([31.728992 35.46901  32.874004 32.92938 ], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample_log_prob = dist.log_prob(sample)\n",
    "print(sample_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_continuous_policy(obs_space, action_space, hidden_layers, activation, scale_diag=1e-2):\n",
    "    Dense = tf.keras.layers.Dense\n",
    "    DistributionLambda = tfp.layers.DistributionLambda\n",
    "    MultivariateNormalDiag = tfd.MultivariateNormalDiag\n",
    "    \n",
    "    policy_net_layers = []\n",
    "    \n",
    "    for i, units in enumerate(hidden_layers):\n",
    "        if i == 0:\n",
    "            policy_net_layers.append(Dense(units, activation=activation, input_shape=obs_space.shape))\n",
    "        else:\n",
    "            policy_net_layers.append(Dense(units, activation=activation))\n",
    "    \n",
    "    policy_net_layers.append(Dense(units=action_space.shape[0]))\n",
    "    policy_net_layers.append(DistributionLambda(\n",
    "        lambda t: MultivariateNormalDiag(loc=t, scale_diag=[scale_diag] * action_space.shape[0])))\n",
    "                                     \n",
    "    return tf.keras.Sequential(policy_net_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalDiag(\"sequential_30_distribution_lambda_30_MultivariateNormalDiag\", batch_shape=[1], event_shape=[1], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCarContinuous-v0\")\n",
    "\n",
    "hidden_layers = [32, 32, 32]\n",
    "activation = \"elu\"\n",
    "\n",
    "policy = build_continuous_policy(env.observation_space, env.action_space, hidden_layers, activation)\n",
    "\n",
    "obs = env.observation_space.sample()\n",
    "\n",
    "action_dist = policy(obs[None,:])\n",
    "print(action_dist)\n",
    "\n",
    "action = action_dist.sample().numpy()\n",
    "assert action[0] in env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Função objetivo em Policy Gradients (*surrogate loss*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Calculando log-prob da escolha da ação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculando retornos de episódios "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Implementação do *surrogate loss*: combinando log-prob e retornos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agente REINFORCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinamento do agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experimentos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
